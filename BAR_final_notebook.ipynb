{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BAR_final_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQWq2xwZ8XiX"
      },
      "source": [
        "Visualization Notebooks:\r\n",
        "\r\n",
        " https://colab.research.google.com/drive/1MkMk1zuP5fbzFmhMeUtpU3joXHXQ91Z9?usp=sharing\r\n",
        "\r\n",
        " https://colab.research.google.com/drive/15IeWoWtLCkWC6-8HlcLy13j22HliyDVY?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1KpvLozumrl"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPBVYJztXGia",
        "outputId": "3467ac5b-3f1e-4918-b22c-34a1247ce8f2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "train_df = pd.read_excel('/content/drive/My Drive/train.xlsx')\r\n",
        "test_df = pd.read_excel('/content/drive/My Drive/test.xlsx')\r\n",
        "test_df_og = pd.read_excel('/content/drive/My Drive/test.xlsx')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC2ygoD9XrR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce68699e-eed7-420a-b105-4a3b3ca52d8f"
      },
      "source": [
        "from fancyimpute import KNN\r\n",
        "from  sklearn.preprocessing import OrdinalEncoder\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnOSWd67urtd"
      },
      "source": [
        "## Convert ordinal data to numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q4sQHQhg7Qt"
      },
      "source": [
        "tenure_dict={'I prefer not to answer':0, \"I don't know\":1, 'Fewer than 10 employees':2, '10 to 19 employees':3,\r\n",
        "             '20 to 99 employees':4, '100 to 499 employees':5, '500 to 999 employees':6, '1,000 to 4,999 employees':7,\r\n",
        "             '5,000 to 9,999 employees':8, '10,000 or more employees':9}\r\n",
        "train_df[\"EmployerSize\"] = train_df[\"EmployerSize\"].replace(tenure_dict)\r\n",
        "test_df[\"EmployerSize\"] = test_df[\"EmployerSize\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={'None':0, 'Less than 10% of projects':1, '10-25% of projects':2,  '26-50% of projects':3,\r\n",
        "             '51-75% of projects':4, '76-99% of projects':5, '100% of projects':6}\r\n",
        "train_df[\"WorkDataVisualizations\"] = train_df[\"WorkDataVisualizations\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkDataVisualizations\"] = test_df[\"WorkDataVisualizations\"].replace(tenure_dict)\r\n",
        "\r\n",
        "title_dict={'Poorly':0, 'Fine':1, 'Perfectly':2}\r\n",
        "train_df[\"TitleFit\"] = train_df[\"TitleFit\"].replace(title_dict)\r\n",
        "test_df[\"TitleFit\"] = test_df[\"TitleFit\"].replace(title_dict)\r\n",
        "\r\n",
        "tenure_dict={\"I don't write code to analyze data\":0, 'Less than a year':1, '1 to 2 years':2, '3 to 5 years':3, '6 to 10 years':4, 'More than 10 years':5}\r\n",
        "train_df[\"Tenure\"] = train_df[\"Tenure\"].replace(tenure_dict)\r\n",
        "test_df[\"Tenure\"] = test_df[\"Tenure\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Don't know\":0, 'Never':1, 'Rarely':2, 'Sometimes':3, 'Most of the time':4, 'Always':5}\r\n",
        "train_df[\"RemoteWork\"] = train_df[\"RemoteWork\"].replace(tenure_dict)\r\n",
        "test_df[\"RemoteWork\"] = test_df[\"RemoteWork\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Don't know\":0, 'Never':1, 'Rarely':2, 'Sometimes':3, 'Most of the time':4, 'Always':5}\r\n",
        "train_df[\"WorkProductionFrequency\"] = train_df[\"WorkProductionFrequency\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkProductionFrequency\"] = test_df[\"WorkProductionFrequency\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Don't know\":0, 'Never':1, 'Rarely':2, 'Sometimes':3, 'Often':4, 'Most of the time':5, 'Always':6}\r\n",
        "train_df[\"WorkToolsFrequencyPython\"] = train_df[\"WorkToolsFrequencyPython\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkToolsFrequencyPython\"] = test_df[\"WorkToolsFrequencyPython\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Don't know\":0, 'Never':1, 'Rarely':2, 'Sometimes':3, 'Often':4, 'Most of the time':5, 'Always':6}\r\n",
        "train_df[\"WorkToolsFrequencyR\"] = train_df[\"WorkToolsFrequencyR\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkToolsFrequencyR\"] = test_df[\"WorkToolsFrequencyR\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Don't know\":1, 'Never':2, 'Rarely':3, 'Sometimes':4, 'Often':5, 'Most of the time':6, 'Always':7}\r\n",
        "train_df[\"WorkToolsFrequencySQL\"] = train_df[\"WorkToolsFrequencySQL\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkToolsFrequencySQL\"] = test_df[\"WorkToolsFrequencySQL\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Don't know\":1, 'Never':2, 'Rarely':3, 'Sometimes':4, 'Often':5, 'Most of the time':6, 'Always':7}\r\n",
        "train_df[\"WorkMethodsFrequencyCross-Validation\"] = train_df[\"WorkMethodsFrequencyCross-Validation\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyCross-Validation\"] = test_df[\"WorkMethodsFrequencyCross-Validation\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkMethodsFrequencyDataVisualization\"] = train_df[\"WorkMethodsFrequencyDataVisualization\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyDataVisualization\"] = test_df[\"WorkMethodsFrequencyDataVisualization\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkMethodsFrequencyDecisionTrees\"] = train_df[\"WorkMethodsFrequencyDecisionTrees\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyDecisionTrees\"] = test_df[\"WorkMethodsFrequencyDecisionTrees\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkMethodsFrequencyLogisticRegression\"] = train_df[\"WorkMethodsFrequencyLogisticRegression\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyLogisticRegression\"] = test_df[\"WorkMethodsFrequencyLogisticRegression\"].replace(tenure_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdv0KHwTj96e"
      },
      "source": [
        "train_df[\"WorkMethodsFrequencyNeuralNetworks\"] = train_df[\"WorkMethodsFrequencyNeuralNetworks\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyNeuralNetworks\"] = test_df[\"WorkMethodsFrequencyNeuralNetworks\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkMethodsFrequencyPCA\"] = train_df[\"WorkMethodsFrequencyPCA\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyPCA\"] = test_df[\"WorkMethodsFrequencyPCA\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkMethodsFrequencyRandomForests\"] = train_df[\"WorkMethodsFrequencyRandomForests\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyRandomForests\"] = test_df[\"WorkMethodsFrequencyRandomForests\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkMethodsFrequencyTimeSeriesAnalysis\"] = train_df[\"WorkMethodsFrequencyTimeSeriesAnalysis\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkMethodsFrequencyTimeSeriesAnalysis\"] = test_df[\"WorkMethodsFrequencyTimeSeriesAnalysis\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyPolitics\"] = train_df[\"WorkChallengeFrequencyPolitics\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyPolitics\"] = test_df[\"WorkChallengeFrequencyPolitics\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyUnusedResults\"] = train_df[\"WorkChallengeFrequencyUnusedResults\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyUnusedResults\"] = test_df[\"WorkChallengeFrequencyUnusedResults\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyDirtyData\"] = train_df[\"WorkChallengeFrequencyDirtyData\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyDirtyData\"] = test_df[\"WorkChallengeFrequencyDirtyData\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyExplaining\"] = train_df[\"WorkChallengeFrequencyExplaining\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyExplaining\"] = test_df[\"WorkChallengeFrequencyExplaining\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyTalent\"] = train_df[\"WorkChallengeFrequencyTalent\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyTalent\"] = test_df[\"WorkChallengeFrequencyTalent\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyClarity\"] = train_df[\"WorkChallengeFrequencyClarity\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyClarity\"] = test_df[\"WorkChallengeFrequencyClarity\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"WorkChallengeFrequencyDataAccess\"] = train_df[\"WorkChallengeFrequencyDataAccess\"].replace(tenure_dict)\r\n",
        "test_df[\"WorkChallengeFrequencyDataAccess\"] = test_df[\"WorkChallengeFrequencyDataAccess\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Not Useful\":1, 'Somewhat useful':2, 'Very useful':3}\r\n",
        "train_df[\"LearningPlatformUsefulnessYouTube\"] = train_df[\"LearningPlatformUsefulnessYouTube\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessYouTube\"] = test_df[\"LearningPlatformUsefulnessYouTube\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"LearningPlatformUsefulnessTextbook\"] = train_df[\"LearningPlatformUsefulnessTextbook\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessTextbook\"] = test_df[\"LearningPlatformUsefulnessTextbook\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"LearningPlatformUsefulnessSO\"] = train_df[\"LearningPlatformUsefulnessSO\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessSO\"] = test_df[\"LearningPlatformUsefulnessSO\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"LearningPlatformUsefulnessProjects\"] = train_df[\"LearningPlatformUsefulnessProjects\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessProjects\"] = test_df[\"LearningPlatformUsefulnessProjects\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"LearningPlatformUsefulnessCourses\"] = train_df[\"LearningPlatformUsefulnessCourses\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessCourses\"] = test_df[\"LearningPlatformUsefulnessCourses\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"LearningPlatformUsefulnessKaggle\"] = train_df[\"LearningPlatformUsefulnessKaggle\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessKaggle\"] = test_df[\"LearningPlatformUsefulnessKaggle\"].replace(tenure_dict)\r\n",
        "\r\n",
        "train_df[\"LearningPlatformUsefulnessBlogs\"] = train_df[\"LearningPlatformUsefulnessBlogs\"].replace(tenure_dict)\r\n",
        "test_df[\"LearningPlatformUsefulnessBlogs\"] = test_df[\"LearningPlatformUsefulnessBlogs\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"I prefer not to answer\":0, 'I did not complete any formal education past high school':1, \"Some college/university study without earning a bachelor's degree\":2, 'Professional degree':3, \"Bachelor's degree\":4, \"Master's degree\":5, \"Doctoral degree\":6}\r\n",
        "train_df[\"FormalEducation\"] = train_df[\"FormalEducation\"].replace(tenure_dict)\r\n",
        "test_df[\"FormalEducation\"] = test_df[\"FormalEducation\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"No\":0, 'Sort of (Explain more)':1, \"Yes\":2}\r\n",
        "train_df['DataScienceIdentitySelect'] = train_df[\"DataScienceIdentitySelect\"].replace(tenure_dict)\r\n",
        "test_df[\"DataScienceIdentitySelect\"] = test_df[\"DataScienceIdentitySelect\"].replace(tenure_dict)\r\n",
        "\r\n",
        "tenure_dict={\"Employed part-time\":0, 'Independent contractor, freelancer, or self-employed':1, \"Employed full-time\":2}\r\n",
        "train_df['EmploymentStatus'] = train_df[\"EmploymentStatus\"].replace(tenure_dict)\r\n",
        "test_df[\"EmploymentStatus\"] = test_df[\"EmploymentStatus\"].replace(tenure_dict)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWtTBp3zT9f0"
      },
      "source": [
        "## Drop Useless Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "artOwGMe6FeJ"
      },
      "source": [
        "train_df = train_df.drop(['ID'], axis = 1) \r\n",
        "test_df = test_df.drop(['ID'], axis = 1) \r\n",
        "\r\n",
        "train_df = train_df.drop(['CodeWriter'], axis = 1) \r\n",
        "test_df = test_df.drop(['CodeWriter'], axis = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfIV4j72oxrb"
      },
      "source": [
        "def isNaN(num):\r\n",
        "    return num != num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSHOYU1avTFt"
      },
      "source": [
        "## New Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXvykXltdWW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8a6349-b080-4307-8a11-b325c0b839b9"
      },
      "source": [
        "i = 0;\r\n",
        "train_df['Number of techniques'] = 0\r\n",
        "for entry in train_df['MLTechniquesSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    train_df['Number of techniques'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    train_df['Number of techniques'][i] = 0\r\n",
        "  else:\r\n",
        "      train_df['Number of techniques'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "i = 0;\r\n",
        "test_df['Number of techniques'] = 0\r\n",
        "for entry in test_df['MLTechniquesSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    test_df['Number of techniques'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    test_df['Number of techniques'][i] = 0\r\n",
        "  else:\r\n",
        "      test_df['Number of techniques'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "\r\n",
        "i = 0;\r\n",
        "train_df['Number of Algor'] = 0\r\n",
        "for entry in train_df['WorkAlgorithmsSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    train_df['Number of Algor'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    train_df['Number of Algor'][i] = 0\r\n",
        "  else:\r\n",
        "      train_df['Number of Algor'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "i = 0;\r\n",
        "test_df['Number of Algor'] = 0\r\n",
        "for entry in test_df['WorkAlgorithmsSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    test_df['Number of Algor'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    test_df['Number of Algor'][i] = 0\r\n",
        "  else:\r\n",
        "      test_df['Number of Algor'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "\r\n",
        "i = 0;\r\n",
        "train_df['Number of Skills'] = 0\r\n",
        "for entry in train_df['MLSkillsSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    train_df['Number of Skills'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    train_df['Number of Skills'][i] = 0\r\n",
        "  else:\r\n",
        "      train_df['Number of Skills'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "i = 0;\r\n",
        "test_df['Number of Skills'] = 0\r\n",
        "for entry in test_df['MLSkillsSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    test_df['Number of Skills'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    test_df['Number of Skills'][i] = 0\r\n",
        "  else:\r\n",
        "      test_df['Number of Skills'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "i = 0;\r\n",
        "train_df['Number of past jobs'] = 0\r\n",
        "for entry in train_df['PastJobTitlesSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    train_df['Number of past jobs'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    train_df['Number of past jobs'][i] = 0\r\n",
        "  else:\r\n",
        "      train_df['Number of past jobs'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "i = 0;\r\n",
        "test_df['Number of past jobs'] = 0\r\n",
        "for entry in test_df['PastJobTitlesSelect']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    test_df['Number of past jobs'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    test_df['Number of past jobs'][i] = 0\r\n",
        "  else:\r\n",
        "      test_df['Number of past jobs'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "\r\n",
        "i = 0;\r\n",
        "train_df['Number of current jobs'] = 0\r\n",
        "for entry in train_df['CurrentEmployerType']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    train_df['Number of current jobs'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    train_df['Number of current jobs'][i] = 0\r\n",
        "  else:\r\n",
        "      train_df['Number of current jobs'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n",
        "\r\n",
        "i = 0;\r\n",
        "test_df['Number of current jobs'] = 0\r\n",
        "for entry in test_df['CurrentEmployerType']:\r\n",
        "  if (isNaN(entry)):\r\n",
        "    test_df['Number of current jobs'][i] = entry\r\n",
        "  elif (entry == \"\"):\r\n",
        "    test_df['Number of current jobs'][i] = 0\r\n",
        "  else:\r\n",
        "      test_df['Number of current jobs'][i] = entry.count(\",\") +1\r\n",
        "  i = 1+i\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT44AzKo8iwg"
      },
      "source": [
        "## One Hot Encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPRMYT8Y8lEn"
      },
      "source": [
        "train_df['CurrentEmployerType'] = train_df['CurrentEmployerType'].fillna(train_df['CurrentEmployerType'].mode()[0])\r\n",
        "test_df['CurrentEmployerType'] = test_df['CurrentEmployerType'].fillna(test_df['CurrentEmployerType'].mode()[0])\r\n",
        "\r\n",
        "concat = train_df['CurrentEmployerType'].str.get_dummies(sep=',').add_prefix('CurrentEmployerType')\r\n",
        "concattest = test_df['CurrentEmployerType'].str.get_dummies(sep=',').add_prefix('CurrentEmployerType')\r\n",
        "\r\n",
        "train_df = pd.concat([train_df, concat], axis=1)\r\n",
        "test_df = pd.concat([test_df, concattest], axis=1)\r\n",
        "\r\n",
        "train_df = train_df.drop(['CurrentEmployerType'], axis = 1) \r\n",
        "test_df = test_df.drop(['CurrentEmployerType'], axis = 1) \r\n",
        "\r\n",
        "train_df['GenderSelect'] = train_df['GenderSelect'].fillna(train_df['GenderSelect'].mode()[0])\r\n",
        "test_df['GenderSelect'] = test_df['GenderSelect'].fillna(test_df['GenderSelect'].mode()[0])\r\n",
        "\r\n",
        "concat = pd.get_dummies(train_df['GenderSelect'], drop_first=True)\r\n",
        "concattest = pd.get_dummies(test_df['GenderSelect'], drop_first=True)\r\n",
        "\r\n",
        "train_df = pd.concat([train_df, concat], axis=1)\r\n",
        "test_df = pd.concat([test_df, concattest], axis=1)\r\n",
        "\r\n",
        "test_df = test_df.drop(['GenderSelect'], axis=1)\r\n",
        "train_df = train_df.drop(['GenderSelect'], axis=1)\r\n",
        "\r\n",
        "\r\n",
        "train_df = train_df.drop(['MLSkillsSelect'], axis = 1) \r\n",
        "test_df = test_df.drop(['MLSkillsSelect'], axis = 1) \r\n",
        "\r\n",
        "train_df = train_df.drop(['MLTechniquesSelect'], axis = 1) \r\n",
        "test_df = test_df.drop(['MLTechniquesSelect'], axis = 1) \r\n",
        "\r\n",
        "train_df = train_df.drop(['WorkAlgorithmsSelect'], axis = 1) \r\n",
        "test_df = test_df.drop(['WorkAlgorithmsSelect'], axis = 1) \r\n",
        "\r\n",
        "train_df = train_df.drop(['PastJobTitlesSelect'], axis = 1) \r\n",
        "test_df = test_df.drop(['PastJobTitlesSelect'], axis = 1) \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62IkpOZvYAV"
      },
      "source": [
        "## Encode remaining columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1WiQA5YHBV"
      },
      "source": [
        "encoder = OrdinalEncoder()\r\n",
        "imputer = KNN()\r\n",
        "\r\n",
        "cat_cols = ['Country', 'CurrentJobTitleSelect', 'MLToolNextYearSelect'\r\n",
        ", 'MLMethodNextYearSelect', 'LanguageRecommendationSelect', 'MajorSelect', 'EmployerIndustry',\r\n",
        "'WorkInternalVsExternalTools', 'WorkMLTeamSeatSelect']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2hl2BEdZz5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22207230-acc4-4338-c697-4033461336c7"
      },
      "source": [
        "\r\n",
        "def encode(data):\r\n",
        "    #function to encode non-null data and replace it in the original data\r\n",
        "    #retains only non-null values\r\n",
        "    nonulls = np.array(data.dropna())\r\n",
        "    #reshapes the data for encoding\r\n",
        "    impute_reshape = nonulls.reshape(-1,1)\r\n",
        "    #encode date\r\n",
        "    impute_ordinal = encoder.fit_transform(impute_reshape)\r\n",
        "    #Assign back encoded values to non-null values\r\n",
        "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\r\n",
        "    return data\r\n",
        "\r\n",
        "#create a for loop to iterate through each column in the data\r\n",
        "for columns in cat_cols:\r\n",
        "    encode(train_df[columns])\r\n",
        "\r\n",
        "for columns in cat_cols:\r\n",
        "    encode(test_df[columns]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcgBE9_2UYOj"
      },
      "source": [
        "## Pop label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9jJbvrOeIVD"
      },
      "source": [
        "train_label = train_df.pop(\"JobSatisfaction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Vi2lXfULqo"
      },
      "source": [
        "## Impute Missing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o49dRDtlbP15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256d5903-2850-4da2-f9d7-5e5a5b30eca1"
      },
      "source": [
        "# impute data and convert \r\n",
        "encode_data = pd.DataFrame(np.round(imputer.fit_transform(train_df)),columns = train_df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imputing row 1/5529 with 21 missing, elapsed time: 17.848\n",
            "Imputing row 101/5529 with 16 missing, elapsed time: 17.930\n",
            "Imputing row 201/5529 with 11 missing, elapsed time: 18.010\n",
            "Imputing row 301/5529 with 14 missing, elapsed time: 18.095\n",
            "Imputing row 401/5529 with 14 missing, elapsed time: 18.181\n",
            "Imputing row 501/5529 with 18 missing, elapsed time: 18.267\n",
            "Imputing row 601/5529 with 14 missing, elapsed time: 18.360\n",
            "Imputing row 701/5529 with 9 missing, elapsed time: 18.453\n",
            "Imputing row 801/5529 with 19 missing, elapsed time: 18.545\n",
            "Imputing row 901/5529 with 15 missing, elapsed time: 18.635\n",
            "Imputing row 1001/5529 with 13 missing, elapsed time: 18.717\n",
            "Imputing row 1101/5529 with 11 missing, elapsed time: 18.802\n",
            "Imputing row 1201/5529 with 11 missing, elapsed time: 18.888\n",
            "Imputing row 1301/5529 with 17 missing, elapsed time: 18.970\n",
            "Imputing row 1401/5529 with 16 missing, elapsed time: 19.056\n",
            "Imputing row 1501/5529 with 26 missing, elapsed time: 19.149\n",
            "Imputing row 1601/5529 with 21 missing, elapsed time: 19.234\n",
            "Imputing row 1701/5529 with 27 missing, elapsed time: 19.317\n",
            "Imputing row 1801/5529 with 10 missing, elapsed time: 19.411\n",
            "Imputing row 1901/5529 with 9 missing, elapsed time: 19.495\n",
            "Imputing row 2001/5529 with 10 missing, elapsed time: 19.575\n",
            "Imputing row 2101/5529 with 18 missing, elapsed time: 19.658\n",
            "Imputing row 2201/5529 with 17 missing, elapsed time: 19.744\n",
            "Imputing row 2301/5529 with 9 missing, elapsed time: 19.831\n",
            "Imputing row 2401/5529 with 12 missing, elapsed time: 19.919\n",
            "Imputing row 2501/5529 with 22 missing, elapsed time: 20.000\n",
            "Imputing row 2601/5529 with 17 missing, elapsed time: 20.089\n",
            "Imputing row 2701/5529 with 12 missing, elapsed time: 20.174\n",
            "Imputing row 2801/5529 with 15 missing, elapsed time: 20.262\n",
            "Imputing row 2901/5529 with 24 missing, elapsed time: 20.341\n",
            "Imputing row 3001/5529 with 7 missing, elapsed time: 20.432\n",
            "Imputing row 3101/5529 with 16 missing, elapsed time: 20.516\n",
            "Imputing row 3201/5529 with 10 missing, elapsed time: 20.604\n",
            "Imputing row 3301/5529 with 20 missing, elapsed time: 20.689\n",
            "Imputing row 3401/5529 with 15 missing, elapsed time: 20.774\n",
            "Imputing row 3501/5529 with 10 missing, elapsed time: 20.861\n",
            "Imputing row 3601/5529 with 4 missing, elapsed time: 20.945\n",
            "Imputing row 3701/5529 with 20 missing, elapsed time: 21.030\n",
            "Imputing row 3801/5529 with 11 missing, elapsed time: 21.115\n",
            "Imputing row 3901/5529 with 15 missing, elapsed time: 21.205\n",
            "Imputing row 4001/5529 with 19 missing, elapsed time: 21.292\n",
            "Imputing row 4101/5529 with 23 missing, elapsed time: 21.377\n",
            "Imputing row 4201/5529 with 14 missing, elapsed time: 21.462\n",
            "Imputing row 4301/5529 with 19 missing, elapsed time: 21.542\n",
            "Imputing row 4401/5529 with 11 missing, elapsed time: 21.625\n",
            "Imputing row 4501/5529 with 15 missing, elapsed time: 21.722\n",
            "Imputing row 4601/5529 with 15 missing, elapsed time: 21.805\n",
            "Imputing row 4701/5529 with 22 missing, elapsed time: 21.888\n",
            "Imputing row 4801/5529 with 14 missing, elapsed time: 21.981\n",
            "Imputing row 4901/5529 with 17 missing, elapsed time: 22.062\n",
            "Imputing row 5001/5529 with 4 missing, elapsed time: 22.141\n",
            "Imputing row 5101/5529 with 9 missing, elapsed time: 22.228\n",
            "Imputing row 5201/5529 with 26 missing, elapsed time: 22.319\n",
            "Imputing row 5301/5529 with 19 missing, elapsed time: 22.412\n",
            "Imputing row 5401/5529 with 19 missing, elapsed time: 22.500\n",
            "Imputing row 5501/5529 with 14 missing, elapsed time: 22.584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBE5bmiWdnbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f871f71-3cf5-4468-d8ee-fea9e83071ab"
      },
      "source": [
        "test_encode = pd.DataFrame(np.round(imputer.fit_transform(test_df)),columns = test_df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imputing row 1/1000 with 11 missing, elapsed time: 0.569\n",
            "Imputing row 101/1000 with 10 missing, elapsed time: 0.596\n",
            "Imputing row 201/1000 with 14 missing, elapsed time: 0.624\n",
            "Imputing row 301/1000 with 22 missing, elapsed time: 0.655\n",
            "Imputing row 401/1000 with 17 missing, elapsed time: 0.685\n",
            "Imputing row 501/1000 with 18 missing, elapsed time: 0.714\n",
            "Imputing row 601/1000 with 12 missing, elapsed time: 0.743\n",
            "Imputing row 701/1000 with 10 missing, elapsed time: 0.787\n",
            "Imputing row 801/1000 with 18 missing, elapsed time: 0.816\n",
            "Imputing row 901/1000 with 8 missing, elapsed time: 0.847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGBr5ejyvdad"
      },
      "source": [
        "## Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCBboVvpfM8d"
      },
      "source": [
        "encode_data= (encode_data - encode_data.min())/(encode_data.max()-encode_data.min()+0.00000000000000000000000000000000000000000000000000001)\r\n",
        "test_encode = (test_encode - test_encode.min())/(test_encode.max()-test_encode.min()+0.00000000000000000000000000000000000000000000000000001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_6K8eyQwRzP"
      },
      "source": [
        "## Apply to voting with regressors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsmEQwxCcUeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9d3141-d66a-4231-b934-b504c8fef1e8"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.neighbors import KNeighborsRegressor\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.ensemble import VotingRegressor\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, x_valid, Y_train, y_valid = train_test_split(encode_data, train_label, test_size=0.20, random_state=11357)\r\n",
        "\r\n",
        "reg1 = GradientBoostingRegressor(random_state=11357)\r\n",
        "reg2 = RandomForestRegressor(random_state=11357)\r\n",
        "reg3 = LinearRegression()\r\n",
        "reg4 = KNeighborsRegressor(n_neighbors=60)\r\n",
        "ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2), ('lr', reg3), ('dl', reg4)])\r\n",
        "\r\n",
        "ereg = ereg.fit(X_train, Y_train)\r\n",
        "pred = ereg.predict(x_valid)\r\n",
        "rms = mean_squared_error(y_valid, pred, squared= False)\r\n",
        "\r\n",
        "this = cross_val_score(ereg,encode_data, train_label, cv=10, scoring = 'neg_root_mean_squared_error')\r\n",
        "print(this)\r\n",
        "print(this.mean())\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.88053647 -1.99315499 -2.05188144 -1.98489421 -1.89119021 -1.98276046\n",
            " -2.02403185 -2.04615849 -2.01588837 -2.13458057]\n",
            "-2.0005077064621837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9De4HOJmEIs"
      },
      "source": [
        "final_prediction = ereg.predict(test_encode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAIv8jGCmF9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12126201-a136-4d66-d1fa-9d8b5f05ff6b"
      },
      "source": [
        "d = {'ID': test_df_og['ID'], 'Prediction':final_prediction}\r\n",
        "test_prediction = pd.DataFrame(data=d)\r\n",
        "test_prediction.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7.898049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>7.660910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6.793064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>6.890519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>7.471687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  Prediction\n",
              "0   1    7.898049\n",
              "1   2    7.660910\n",
              "2   3    6.793064\n",
              "3   4    6.890519\n",
              "4   5    7.471687"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyni-tzImMrp"
      },
      "source": [
        "with open('/content/drive/My Drive/38.cvs', 'w') as f:\r\n",
        "  test_prediction.to_csv(f, index = False)  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}